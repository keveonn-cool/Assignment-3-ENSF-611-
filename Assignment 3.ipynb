{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 3: Non-Linear Models and Validation Metrics (37 total marks)\n",
    "### Due: October 24 at 11:59pm\n",
    "\n",
    "### Name: Gopal Sharma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses non-linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf275ca7",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b67a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee2d2c3",
   "metadata": {},
   "source": [
    "## Part 1: Regression (14.5 marks)\n",
    "\n",
    "For this section, we will be continuing with the concrete example from yellowbrick. You will need to compare these results to the results from the previous assignment. Please use the results from the solution if you were unable to complete Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8219f163",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (0.5 marks)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the concrete dataset into the feature matrix `X` and target vector `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2af8bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Import concrete dataset from yellowbrick library\n",
    "from yellowbrick.datasets import load_concrete\n",
    "X, y = load_concrete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fea4cc",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (0 marks)\n",
    "\n",
    "Data processing was completed in the previous assignment. No need to repeat here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a245d00",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import the Decision Tree, Random Forest and Gradient Boosting Machines regression models from sklearn\n",
    "2. Instantiate the three models with `max_depth = 5`. Are there any other parameters that you will need to set?\n",
    "3. Implement each machine learning model with `X` Iand `y`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "626b90cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(max_depth=5, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(max_depth=5, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(max_depth=5, random_state=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.2)\n",
    "\n",
    "# Initialize the regression models with max_depth = 5\n",
    "decision_tree = DecisionTreeRegressor(max_depth=5, random_state=0)\n",
    "random_forest = RandomForestRegressor(max_depth=5, random_state=0)\n",
    "gradient_boosting = GradientBoostingRegressor(max_depth=5, random_state=0)\n",
    "\n",
    "# Fit the models to the training data\n",
    "decision_tree.fit(X_train, y_train)\n",
    "random_forest.fit(X_train, y_train)\n",
    "gradient_boosting.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f994e31",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model\n",
    "\n",
    "Calculate the average training and validation accuracy using mean squared error with cross-validation. To do this, you will need to set `scoring='neg_mean_squared_error'` in your `cross_validate` function and negate the results (multiply by -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93d2a4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Model:\n",
      "Training MSE: 47.823\n",
      "Validation MSE: 74.045\n",
      "\n",
      "Random Forest Model:\n",
      "Training MSE: 30.296\n",
      "Validation MSE: 47.615\n",
      "\n",
      "Gradient Boosting Model:\n",
      "Training MSE: 3.694\n",
      "Validation MSE: 23.547\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Perform cross-validation and calculate mean squared error for Decision Tree\n",
    "cv_results_dt = cross_validate(decision_tree, X_train, y_train, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "\n",
    "# Calculate the mean training and validation MSE for Decision Tree\n",
    "train_mse_dt = cv_results_dt['train_score'].mean() * -1\n",
    "validation_mse_dt = cv_results_dt['test_score'].mean() * -1\n",
    "\n",
    "# Print the results for Decision Tree\n",
    "print(\"Decision Tree Model:\")\n",
    "print(f\"Training MSE: {train_mse_dt:.3f}\")\n",
    "print(f\"Validation MSE: {validation_mse_dt:.3f}\")\n",
    "\n",
    "# Perform cross-validation and calculate mean squared error for Random Forest\n",
    "cv_results_rf = cross_validate(random_forest, X_train, y_train, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "\n",
    "# Calculate the mean training and validation MSE for Random Forest\n",
    "train_mse_rf = cv_results_rf['train_score'].mean() * -1\n",
    "validation_mse_rf = cv_results_rf['test_score'].mean() * -1\n",
    "\n",
    "# Print the results for Random Forest\n",
    "print(\"\\nRandom Forest Model:\")\n",
    "print(f\"Training MSE: {train_mse_rf:.3f}\")\n",
    "print(f\"Validation MSE: {validation_mse_rf:.3f}\")\n",
    "\n",
    "# Perform cross-validation and calculate mean squared error for Gradient Boosting\n",
    "cv_results_gb = cross_validate(gradient_boosting, X_train, y_train, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "\n",
    "# Calculate the mean training and validation MSE for Gradient Boosting\n",
    "train_mse_gb = cv_results_gb['train_score'].mean() * -1\n",
    "validation_mse_gb = cv_results_gb['test_score'].mean() * -1\n",
    "\n",
    "# Print the results for Gradient Boosting\n",
    "print(\"\\nGradient Boosting Model:\")\n",
    "print(f\"Training MSE: {train_mse_gb:.3f}\")\n",
    "print(f\"Validation MSE: {validation_mse_gb:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc3f7a8",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: DT, RF and GB\n",
    "2. Add the accuracy results to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c0965b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Training MSE Validation MSE\n",
      "Decision Tree        47.822974      74.045335\n",
      "Random Forest        30.296363      47.614708\n",
      "Gradient Boosting     3.694308        23.5465\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "from sklearn.model_selection import cross_validate\n",
    "import pandas as pd\n",
    "\n",
    "# Define the models with max depth and random state\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeRegressor(max_depth=5, random_state=0),\n",
    "    \"Random Forest\": RandomForestRegressor(max_depth=5, random_state=0),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(max_depth=5, random_state=0)\n",
    "}\n",
    "\n",
    "# Initialize an empty DataFrame to store the results\n",
    "results = pd.DataFrame(columns=[\"Training MSE\", \"Validation MSE\"], index=models.keys())\n",
    "\n",
    "# Perform cross-validation and calculate mean squared errors\n",
    "for model_name, model in models.items():\n",
    "    cv_results = cross_validate(model, X_train, y_train, cv=5, scoring=\"neg_mean_squared_error\", return_train_score=True)\n",
    "    \n",
    "    # Calculate average training and validation MSE and store in the DataFrame\n",
    "    train_mse = -cv_results[\"train_score\"].mean()\n",
    "    validation_mse = -cv_results[\"test_score\"].mean()\n",
    "    results.loc[model_name] = [train_mse, validation_mse]\n",
    "\n",
    "# Print the results DataFrame\n",
    "print(results)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc93a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31715a9d",
   "metadata": {},
   "source": [
    "Repeat the step above to print the R2 score instead of the mean-squared error. For this case, you can use `scoring='r2'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83539f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Training R2 Score Validation R2 Score\n",
      "Decision Tree              0.830437            0.735184\n",
      "Random Forest              0.892634            0.830004\n",
      "Gradient Boosting          0.986903            0.916155\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "from sklearn.model_selection import cross_validate\n",
    "import pandas as pd\n",
    "\n",
    "# Define the models with max depth and random state\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeRegressor(max_depth=5, random_state=0),\n",
    "    \"Random Forest\": RandomForestRegressor(max_depth=5, random_state=0),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(max_depth=5, random_state=0)\n",
    "}\n",
    "\n",
    "# Initialize an empty DataFrame to store the results\n",
    "results = pd.DataFrame(columns=[\"Training R2 Score\", \"Validation R2 Score\"], index=models.keys())\n",
    "\n",
    "# Perform cross-validation and calculate R2 scores\n",
    "for model_name, model in models.items():\n",
    "    cv_results = cross_validate(model, X_train, y_train, cv=5, scoring='r2', return_train_score=True)\n",
    "    \n",
    "    # Calculate average training and validation R2 scores and store in the DataFrame\n",
    "    train_r2 = cv_results[\"train_score\"].mean()\n",
    "    validation_r2 = cv_results[\"test_score\"].mean()\n",
    "    results.loc[model_name] = [train_r2, validation_r2]\n",
    "\n",
    "# Print the results DataFrame\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5257a98",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "1. How do these results compare to the results using a linear model in the previous assignment? Use values.\n",
    "1. Out of the models you tested, which model would you select for this dataset and why?\n",
    "1. If you wanted to increase the accuracy of the tree-based models, what would you do? Provide two suggestions.\n",
    "\n",
    "*ANSWER HERE*\n",
    "1) In contrast to the linear regression model used in the previous assignment, the non-linear models (Decision Tree, Random Forest, and Gradient Boosting) demonstrated notably superior performance on the concrete dataset. They achieved significantly higher R2 scores, indicating improved model performance. For instance, the Gradient Boosting model exhibited exceptional R2 scores of 0.988 for training and 0.919 for validation, whereas the linear model attained R2 scores of only 0.61. Furthermore, the non-linear models outperformed the linear model in terms of mean squared error (MSE) scores, yielding lower MSE values.\n",
    "\n",
    "2) The optimal choice for this dataset, as per our analysis, would be the Gradient Boosting model. It outperformed the other models by achieving the highest R2 scores and the lowest mean squared error. The Gradient Boosting model demonstrated an impressive training R2 score of 0.988, a strong validation R2 score of 0.919, a low training MSE of 3.379, and a minimal validation MSE of 22.783. These results signify its ability to generalize effectively and deliver the most favorable overall performance.\n",
    "\n",
    "3) To enhance the accuracy of tree-based models, there are several parameter adjustments that can be made. For decision trees, modifying parameters like max_depth can have a significant impact. Increasing the max_depth allows for more nodes in the tree, which may lead to heightened accuracy. In the case of Random Forest, adjustments to parameters such as n_estimators and max_features can be beneficial. Raising the number of trees (n_estimators) can provide more robust results, while restricting the consideration of features (max_features) introduces more randomness and can contribute to enhanced model performance. These parameter adjustments are essential for fine-tuning the models and improving their accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b238f4",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?\n",
    "\n",
    "\n",
    "\n",
    "Answer: My approach to completing this assignment involved the following steps:\n",
    "\n",
    "Understanding Non-Linear Models: I began by reviewing the lecture slides and materials provided to comprehend the theoretical concepts related to non-linear models. This included understanding their purpose and the various types of non-linear models available.\n",
    "\n",
    "Exploring Lecture Materials: I utilized the lecture materials provided in D2L, such as slides and Jupyter notebooks, to gather foundational knowledge about the non-linear models, as well as the procedures and code examples used in Python.\n",
    "\n",
    "Consulting ChatGPT: During the coding process, I sought guidance from ChatGPT on several occasions. I used prompts to understand cross-validation scores, their implementation in Python, how to write a loop to populate a pandas DataFrame, and the key distinctions between linear and non-linear machine learning models. ChatGPT was instrumental in providing clarification on these topics.\n",
    "\n",
    "Source of Code: The primary source of the code I used was from the example Jupyter notebooks provided on D2L. These notebooks served as valuable references and starting points for implementing the machine learning models and performing cross-validation.\n",
    "\n",
    "As for the generative AI tools, I used the ChatGPT API for assistance during the assignment. The prompts I used with ChatGPT helped me understand and implement Python code effectively, especially when dealing with errors and conceptual challenges. ChatGPT was a valuable resource in providing guidance and resolving issues.\n",
    "\n",
    "Challenges Faced:\n",
    "I encountered challenges during the assignment, particularly at the beginning. One notable challenge was related to my use of the wrong class. Instead of employing the DecisionTreeRegressor, I initially used DecisionTreeClassifier. This resulted in code errors and hindered my progress. ChatGPT was instrumental in correcting this error by guiding me to use the correct class for regression.\n",
    "\n",
    "Citations:\n",
    "\n",
    "OpenAI. (2023). ChatGPT API. Retrieved from https://www.openai.com/chatgpt-api\n",
    "Dawson, Leanne. (2023). ENSF 611 L01 - (Fall 2023) - Machine Learning for Software Engineers - F2023ENSF611L01. In Desire2Learn (Brightspace). [D2L Link]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93097bfe",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 2: Classification (17.5 marks)\n",
    "\n",
    "You have been asked to develop code that can help the user classify different wine samples. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (2 marks)\n",
    "\n",
    "The data used for this task can be downloaded from UCI: https://archive.ics.uci.edu/dataset/109/wine\n",
    "\n",
    "Use the pandas library to load the dataset. You must define the column headers if they are not included in the dataset \n",
    "\n",
    "You will need to split the dataset into feature matrix `X` and target vector `y`. Which column represents the target vector?\n",
    "\n",
    "Print the size and type of `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33583c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size and type of X: 2314, <class 'pandas.core.frame.DataFrame'>\n",
      "Size and type of y: 178, <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "import os  # Don't forget to import the 'os' module\n",
    "\n",
    "# Define the URL of the wine dataset\n",
    "wine_data_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data'\n",
    "\n",
    "# Download the dataset if it's not already available\n",
    "def download_file(url, filename):\n",
    "    if not os.path.isfile(filename):\n",
    "        print(f\"Downloading {filename} from {url}\")\n",
    "        urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "# Define the column headers for the dataset\n",
    "column_names = ['Class', 'Alcohol', 'MalicAcid', 'Ash', 'AlcalinityOfAsh', 'Magnesium',\n",
    "                'TotalPhenols', 'Flavanoids', 'NonflavanoidPhenols', 'Proanthocyanins', 'ColorIntensity',\n",
    "                'Hue', 'OD280_OD315_ofDilutedWines', 'Proline']\n",
    "\n",
    "# Download and load the dataset\n",
    "download_file(wine_data_url, 'wine_data.csv')\n",
    "data = pd.read_csv('wine_data.csv', names=column_names, na_values='?')\n",
    "\n",
    "# Split the dataset into feature matrix X and target vector y\n",
    "X = data.drop(columns=['Class'])\n",
    "y = data['Class']\n",
    "\n",
    "# Print the size and type of X and y\n",
    "print(f\"Size and type of X: {X.size}, {type(X)}\")\n",
    "print(f\"Size and type of y: {y.size}, {type(y)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (1.5 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28af110",
   "metadata": {},
   "source": [
    "Print the first five rows of the dataset to inspect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea266921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Class  Alcohol  MalicAcid   Ash  AlcalinityOfAsh  Magnesium  TotalPhenols  \\\n",
      "0      1    14.23       1.71  2.43             15.6        127          2.80   \n",
      "1      1    13.20       1.78  2.14             11.2        100          2.65   \n",
      "2      1    13.16       2.36  2.67             18.6        101          2.80   \n",
      "3      1    14.37       1.95  2.50             16.8        113          3.85   \n",
      "4      1    13.24       2.59  2.87             21.0        118          2.80   \n",
      "\n",
      "   Flavanoids  NonflavanoidPhenols  Proanthocyanins  ColorIntensity   Hue  \\\n",
      "0        3.06                 0.28             2.29            5.64  1.04   \n",
      "1        2.76                 0.26             1.28            4.38  1.05   \n",
      "2        3.24                 0.30             2.81            5.68  1.03   \n",
      "3        3.49                 0.24             2.18            7.80  0.86   \n",
      "4        2.69                 0.39             1.82            4.32  1.04   \n",
      "\n",
      "   OD280_OD315_ofDilutedWines  Proline  \n",
      "0                        3.92     1065  \n",
      "1                        3.40     1050  \n",
      "2                        3.17     1185  \n",
      "3                        3.45     1480  \n",
      "4                        2.93      735  \n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "print(data.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834fc8fe",
   "metadata": {},
   "source": [
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97c6e9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class                         0\n",
       "Alcohol                       0\n",
       "MalicAcid                     0\n",
       "Ash                           0\n",
       "AlcalinityOfAsh               0\n",
       "Magnesium                     0\n",
       "TotalPhenols                  0\n",
       "Flavanoids                    0\n",
       "NonflavanoidPhenols           0\n",
       "Proanthocyanins               0\n",
       "ColorIntensity                0\n",
       "Hue                           0\n",
       "OD280_OD315_ofDilutedWines    0\n",
       "Proline                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070956af",
   "metadata": {},
   "source": [
    "How many samples do we have of each type of wine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b37a6fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "2    71\n",
      "1    59\n",
      "3    48\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `SVC` and `DecisionTreeClassifier` from sklearn\n",
    "2. Instantiate models as `SVC()` and `DecisionTreeClassifier(max_depth = 3)`\n",
    "3. Implement the machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7167159d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Initialize and train the Support Vector Classifier (SVC)\n",
    "svc = SVC(random_state=0)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# Initialize and train the Decision Tree Classifier with a maximum depth of 3\n",
    "tree_dt = DecisionTreeClassifier(max_depth=3)\n",
    "tree_dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0870b0d2",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model \n",
    "\n",
    "Calculate the average training and validation accuracy using `cross_validate` for the two different models listed in Step 3. For this case, use `scoring='accuracy'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff23f928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier:\n",
      "Training Accuracy: 0.994\n",
      "Validation Accuracy: 0.894\n",
      "\n",
      "Support Vector Classifier (SVC):\n",
      "Training Accuracy: 0.680\n",
      "Validation Accuracy: 0.677\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Perform cross-validation for the Decision Tree Classifier\n",
    "cv_results_dt = cross_validate(tree_dt, X_train, y_train, cv=5, scoring='accuracy', return_train_score=True)\n",
    "\n",
    "# Perform cross-validation for the Support Vector Classifier (SVC)\n",
    "cv_results_svc = cross_validate(svc, X_train, y_train, cv=5, scoring='accuracy', return_train_score=True)\n",
    "\n",
    "# Calculate the mean training accuracy and validation accuracy for the Decision Tree Classifier\n",
    "train_accuracy_dt = cv_results_dt['train_score'].mean()\n",
    "validation_accuracy_dt = cv_results_dt['test_score'].mean()\n",
    "\n",
    "# Calculate the mean training accuracy and validation accuracy for the Support Vector Classifier (SVC)\n",
    "train_accuracy_svc = cv_results_svc['train_score'].mean()\n",
    "validation_accuracy_svc = cv_results_svc['test_score'].mean()\n",
    "\n",
    "# Print the results\n",
    "print(\"Decision Tree Classifier:\")\n",
    "print(f\"Training Accuracy: {train_accuracy_dt:.3f}\")\n",
    "print(f\"Validation Accuracy: {validation_accuracy_dt:.3f}\\n\")\n",
    "\n",
    "print(\"Support Vector Classifier (SVC):\")\n",
    "print(f\"Training Accuracy: {train_accuracy_svc:.3f}\")\n",
    "print(f\"Validation Accuracy: {validation_accuracy_svc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0bbd83",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "#### Step 5.1: Compare Models\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be4b5c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Data Size  Training Accuracy  Validation Accuracy\n",
      "Decision Tree       2314           0.994357             0.894017\n",
      "SVC                 2314           0.680427             0.676638\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "\n",
    "results = pd.DataFrame(columns=['Data Size', 'Training Accuracy', 'Validation Accuracy'], index=['Decision Tree', 'SVC'])\n",
    "results[\"Training Accuracy\"] = [train_accuracy_dt, train_accuracy_svc]\n",
    "results[\"Validation Accuracy\"] = [validation_accuracy_dt, validation_accuracy_svc]\n",
    "results[\"Data Size\"] = [X.size, X.size]\n",
    "\n",
    "# Print the results DataFrame\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e17878",
   "metadata": {},
   "source": [
    "#### Step 5.2: Visualize Classification Errors\n",
    "Which method gave the highest accuracy? Use this method to print the confusion matrix and classification report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44b091a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14  2  0]\n",
      " [ 0 20  1]\n",
      " [ 0  0  8]]\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Implement best model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred =tree_dt.predict(X_val)\n",
    "mat = confusion_matrix(y_val, y_pred)\n",
    "print(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09d21b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TO DO: Print confusion matrix using a heatmap\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate the confusion matrix\n",
    "confusion_matrix = mat\n",
    "\n",
    "# Define class labels\n",
    "class_labels = [1, 2, 3]\n",
    "\n",
    "# Create a heatmap of the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix, xticklabels=class_labels, yticklabels=class_labels, square=True, annot=True, cbar=False)\n",
    "plt.xlabel('Predicted Value')\n",
    "plt.ylabel('True Value')\n",
    "plt.title(\"Confusion Matrix as Heatmap\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ef95947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.88      0.93        16\n",
      "           2       0.91      0.95      0.93        21\n",
      "           3       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.93      0.94      0.93        45\n",
      "weighted avg       0.94      0.93      0.93        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Print classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_val,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf319621",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "1. How do the training and validation accuracy change depending on the method used? Explain with values.\n",
    "1. What are two reasons why the support vector machines model did not work as well as the tree-based model?\n",
    "1. How many samples were incorrectly classified in step 5.2? \n",
    "1. In this case, is maximizing precision or recall more important? Why?\n",
    "\n",
    "*YOUR ANSWERS HERE*\n",
    "1. The training and validation accuracy varied significantly between the Decision Tree Classifier and the Support Vector Machine (SVC) models. For the Decision Tree Classifier, the training accuracy was approximately 0.994, while the validation accuracy was about 0.902. In contrast, the SVC model had a training accuracy of approximately 0.6804 and a validation accuracy of around 0.6766. The Decision Tree Classifier outperforms the SVC model in terms of both training and validation accuracy.\n",
    "\n",
    "2. Two reasons why the SVC model did not work as well as the Decision Tree Classifier are:\n",
    "\n",
    "a. Improper tuning of hyperparameters: The performance of SVC is highly dependent on hyperparameters like 'C' and 'gamma.' If these parameters are not tuned correctly, it can lead to suboptimal results. In this case, the hyperparameters might not have been fine-tuned for the SVC model.\n",
    "\n",
    "b. Sensitivity to feature scaling: SVC is sensitive to the scaling of features. Since the wine dataset contains features with a wide range of values (e.g., some features range from 0.1 to 1000), failing to scale the features properly can affect the model's performance. Decision Trees, on the other hand, are less sensitive to feature scaling.\n",
    "\n",
    "3. In step 5.2, three samples were incorrectly classified.\n",
    "\n",
    "4. In this case, maximizing precision is more important. Precision measures the accuracy of positive predictions, and in the context of classifying wine cultivars, it's crucial to minimize the false positives, i.e., incorrectly labeling wine as a certain cultivar when it's not. Maximizing precision ensures that the positive predictions are as accurate as possible, which is essential for wine classification and quality assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664ff8ae",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e837da",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Process Description\n",
    "\n",
    "For this assignment, I started by reviewing the lecture notes and materials provided on Support Vector Machines (SVM) and Decision Trees to gain a thorough understanding of these machine learning models. I also referred to the Jupyter notebooks available on D2L to see code examples that helped me in the implementation.\n",
    "\n",
    "I utilized ChatGPT to clarify concepts, troubleshoot errors, and get a better understanding of the code. Some of the prompts I used included inquiring about the significance of the gamma parameter in the SVM model, understanding the key differences between Random Forest and Decision Trees, and learning how to efficiently write code for creating and populating a Pandas DataFrame.\n",
    "\n",
    "During the assignment, I encountered a challenge in comprehending the different kernel functions available for SVM models, particularly the polynomial kernel and the RBF/Gaussian kernel. ChatGPT was instrumental in clearing up my understanding of these kernels.\n",
    "\n",
    "Citations:\n",
    "\n",
    "OpenAI. (2023). ChatGPT API. Retrieved from https://www.openai.com/chatgpt-api\n",
    "Dawson, Leanne. (2023). ENSF 611 L01 - (Fall 2023) - Machine Learning for Software Engineers - F2023ENSF611L01. In Desire2Learn (Brightspace). https://d2l.ucalgary.ca/d2l/home/543310*DESCRIBE YOUR PROCESS HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd7358d",
   "metadata": {},
   "source": [
    "## Part 3: Observations/Interpretation (3 marks)\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "\n",
    "*ADD YOUR FINDINGS HERE*\n",
    "In Part 1, we explored the performance of Decision Tree, Random Forest, and Gradient Boosting models, each set to a maximum depth of 5.\n",
    "\n",
    "Decision Tree: This basic model exhibited modest results with a training score (R2) of 0.834 and a validation score of 0.739. However, it can be prone to overfitting.\n",
    "\n",
    "Random Forest: Random Forest, an ensemble of Decision Trees, improved performance. It achieved a training score of 0.897 and a validation score of 0.841, effectively reducing overfitting.\n",
    "\n",
    "Gradient Boosting: Gradient Boosting excelled with a training score of 0.988 and a validation score of 0.919. Its iterative approach and strong pre-pruning make it a powerful model.\n",
    "\n",
    "The pattern here emphasizes the advantages of ensemble models over basic Decision Trees and aligns with the concept of ensembles discussed in lectures.\n",
    "\n",
    "Part 2: Decision Tree vs. Support Vector Machines (SVM)\n",
    "\n",
    "In Part 2, a Decision Tree model with a maximum depth of 3 outperformed an SVM model.\n",
    "\n",
    "Decision Tree: Achieved better training and validation accuracy, making it a good match for the dataset's characteristics.\n",
    "\n",
    "Support Vector Machines (SVM): Underperformed due to inadequate parameter tuning and feature scaling. SVMs are sensitive to these factors.\n",
    "\n",
    "These results illustrate the importance of selecting the right model and fine-tuning parameters for optimal performance, aligning with lecture content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97b6ac",
   "metadata": {},
   "source": [
    "## Part 4: Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "*ADD YOUR THOUGHTS HERE*\n",
    "During this assignment, I appreciated the opportunity to explore various machine learning models and delve into the underlying theory. It was fascinating to witness how different models can be applied based on the dataset characteristics to achieve accuracy.\n",
    "\n",
    "The complex mathematical aspects of the models presented a considerable challenge. While I attempted to grasp the mathematical intricacies, I found them to be quite daunting and difficult to fully comprehend. The mathematical components of machine learning remain an area where I see room for growth and improvement in my understanding.\n",
    "\n",
    "In conclusion, I found this assignment to be a valuable learning experience that exposed me to the diverse world of machine learning, both its strengths and complexities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa21e53b",
   "metadata": {},
   "source": [
    "## Part 5: Bonus Question (3 marks)\n",
    "\n",
    "Repeat Part 2 and compare the support vector machines model used to `LinearSVC(max_iter=5000)`. Does using `LinearSVC` improve the results? Why or why not?\n",
    "\n",
    "Is `LinearSVC` a good fit for this dataset? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30fea72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ranji\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Ranji\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Ranji\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Ranji\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Ranji\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Ranji\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Ranji\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Ranji\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Ranji\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Ranji\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Ranji\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Ranji\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Size for Training</th>\n",
       "      <th>Data Size for Testing</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(133, 13)</td>\n",
       "      <td>(45, 13)</td>\n",
       "      <td>0.932217</td>\n",
       "      <td>0.917949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Data Size for Training Data Size for Testing  Training Accuracy  \\\n",
       "0              (133, 13)              (45, 13)           0.932217   \n",
       "\n",
       "   Validation Accuracy  \n",
       "0             0.917949  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Create and fit the LinearSVC model\n",
    "LinearSVC_m = LinearSVC(max_iter=5000).fit(X_train, y_train)\n",
    "\n",
    "# Perform cross-validation for LinearSVC\n",
    "cv_results_m_score = cross_validate(LinearSVC_m, X_train, y_train, cv=5, scoring='accuracy', return_train_score=True)\n",
    "cv_results_train = cv_results_m_score[\"train_score\"].mean()\n",
    "cv_result_test = cv_results_m_score[\"test_score\"].mean()\n",
    "\n",
    "# Create a results DataFrame to compare LinearSVC with the previous model\n",
    "results = pd.DataFrame(columns=['Data Size for Training', 'Data Size for Testing', 'Training Accuracy', 'Validation Accuracy'])\n",
    "results['Data Size for Training'] = [X_train.shape]\n",
    "results['Data Size for Testing'] = [X_val.shape]\n",
    "results['Training Accuracy'] = [cv_results_train]\n",
    "results['Validation Accuracy'] = [cv_result_test]\n",
    "\n",
    "display(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabc68a4",
   "metadata": {},
   "source": [
    "*ANSWER HERE*\n",
    "The LinearSVC model is a better fit for this dataset than the SVC model. It achieves higher training and validation accuracies, with the training accuracy at 0.887 and the validation accuracy at 0.872. In contrast, the SVC model has lower training and validation accuracies, with training accuracy at 0.680 and validation accuracy at 0.677.\n",
    "\n",
    "The dataset seems to be more compatible with a linear decision boundary, which LinearSVC provides, as it excels in datasets where linear separation works well. The SVC model offers multiple kernel functions, including linear, polynomial, and radial basis functions, but these complex kernels may not be necessary for this dataset.\n",
    "\n",
    "In summary, LinearSVC is a better choice for this dataset due to its higher accuracy and its suitability for datasets that benefit from a linear decision boundary."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
